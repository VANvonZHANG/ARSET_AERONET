{"cells":[{"cell_type":"markdown","metadata":{"id":"_JoDqu-wN15W"},"source":["- **Module:** read_and_map_aeronet_interactive.ipynb\n","- **Authors:** Petar Grigorov, Alqamah Sayeed, and Pawan Gupta\n","- **Organization:** NASA AERONET (https://aeronet.gsfc.nasa.gov/)\n","- **Date:** 09/28/2023\n","- **Last Revision:** 07/29/2024\n","- **Purpose:** To access and map the AERONET data from Web API\n","- **Disclaimer:** The code is for demonstration purposes only. Users are responsible to check for accuracy and revise to fit their objective.\n","- **Contact:** Report any concern or question related to the code to pawan.gupta@nasa.gov or petar.t.grigorov@nasa.gov\n","- **Readme:** https://github.com/pawanpgupta/AERONET/blob/Python/README/Read_and_map_AERONET"]},{"cell_type":"markdown","metadata":{"id":"CzzFuiyGzBEr"},"source":["**Required packages installation and importing**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RdEwG0LLR4KW"},"outputs":[],"source":["!pip uninstall -y numpy pandas shapely\n","!pip install numpy==1.26.4 pandas==2.0.3 shapely==1.8.5\n","!pip install cartopy\n","!pip install beautifulsoup4\n","!pip install requests\n","!pip install geopandas\n","!pip install ipywidgets\n","\n","from bs4 import BeautifulSoup      #reads data from website (web scraping)\n","import re                          #regular expression matching operations (RegEx)\n","import requests                    #useful for sending HTTP requests using python\n","import shutil                      #useful for creating zip files\n","import numpy as np                 #for array manipulation\n","import datetime                    #for time data manipulation\n","import pandas as pd                #for data querying and processing\n","import geopandas as gpd            #same as pandas, but for geospatial data\n","import matplotlib.pyplot as plt    #for creating plots\n","\n","import cartopy.crs as ccrs         #for creating geographical maps\n","import cartopy.feature as cfeature\n","from copy import deepcopy\n","\n","from ipywidgets import interact, widgets  #for creating fun widgets\n","from IPython.display import display, HTML\n","import matplotlib.animation as animation\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from google.colab import drive      #imports local google drive\n","drive.mount('/drive')               #mounts local google drive onto colab"]},{"cell_type":"markdown","metadata":{"id":"NWd23a3vN7v9"},"source":["**Setup input parameters such as date, data level, averaging type, AOD range for mapping, AOD/Angstrom exponent, and geographical limits**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eDPyzlBzN6kF"},"outputs":[],"source":["dt_initial = '20240627'                 #starting date YYYYMMDD format\n","dt_final = '20240714'                   #final date YYYYMMDD format\n","level = 1.5                             #AERONET data level (1.0, 1.5 or 2.0)\n","average_type = 'daily'                  #Specifies data aggregation (daily or hourly)\n","vis_min = 0.0                           #any AOD/AE with smaller value will show as green on the color map, adjust as necessary\n","vis_max = 1.0                           #any AOD/AE with larger value will show as red on the color map, adjust as necessary\n","feature_choice = 2                      #Enter (1) if specifying an AOD wavelength or (2) if specifying an Angstrom exponent\n","wavelength = 500                        #Available choices: 1640, 1020, 870, 865, 779, 675, 667, 620, 560, 555, 551, 532, 531, 510, 500, 490, 443, 440, 412, 400, 380, 340\n","Angstrom_exp = '440-675'                #Available choices: '440-870','380-500','440-675','500-870','340-440','440-675(Polar)'\n","#Bounding box: Coordinates must be in decimal degrees (including decimal)\n","lat1,lon1 = 23.,-135.                   #lat1,lon1 - Lower Left\n","lat2,lon2 = 53.,-65.                    #lat2,lon2 - Upper Right"]},{"cell_type":"markdown","metadata":{"id":"5CSmQFb4zpzV"},"source":["**Get desired AERONET data using web services, then scraping data from website**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z8AgFuQ8Sxy_"},"outputs":[],"source":["yr_initial = dt_initial[:4]               #initial year\n","mon_initial = dt_initial[4:6]             #initial month\n","day_initial = dt_initial[6:]              #initial day\n","\n","yr_final = dt_final[:4]                   #final year\n","mon_final = dt_final[4:6]                 #final month\n","day_final = dt_final[6:]                  #final day\n","\n","if level == 1 or level == 1.0:\n","  lev = 10\n","elif level == 1.5:\n","  lev = 15\n","elif level == 2 or level == 2.0:\n","  lev = 20\n","else:\n","  print(\"\\nIncorrect input for data level type. Defaulting to level 1.5\")\n","  lev = 15\n","\n","if lev == 20 and int(yr_initial) == datetime.date.today().year:               #if user wants level 2 data for the current year, program alerts that data may not be available\n","  lev = 15                                                                      #defaults to level 1.5 data\n","  print(\"\\nThere is no level 2 data available for the current year. Defaulting to level 1.5 data\")\n","\n","url = 'https://aeronet.gsfc.nasa.gov/cgi-bin/print_web_data_v3?lat1='+str(lat1)+'&lon1='+str(lon1)+'&lat2='+str(lat2)+'&lon2='+str(lon2)+'&year='+yr_initial+'&month='+mon_initial+'&day='+day_initial+'&year2='+yr_final+'&month2='+mon_final+'&day2='+day_final+'&AOD'+str(lev)+'=1&AVG=10'\n","soup = BeautifulSoup(requests.get(url).text) #web services contents are read here from URL"]},{"cell_type":"markdown","metadata":{"id":"ceWvm1KA00QN"},"source":["**Read and filter downloaded data as per user average type specification**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aJ8zNaz5S48f"},"outputs":[],"source":["with open(r'/content/temp.txt' ,\"w\") as oFile:          #writes the data scraped from \"beautiful soup\" to a text file on your local Google drive\n","    oFile.write(str(soup.text))\n","    oFile.close()\n","\n","df = pd.read_csv(r'/content/temp.txt',skiprows = 5)     #loads the csv data into a Pandas dataframe\n","!rm temp.txt\n","\n","if len(df) > 0:\n","  df = df.replace(-999.0, np.nan)                                     #replaces all -999.0 vakyes with NaN; helps with accurate data aggregation\n","  df.rename(columns={'Site_Latitude(Degrees)': 'Site_Latitude', 'Site_Longitude(Degrees)': 'Site_Longitude'}, inplace = True)\n","  df[['Day','Month','Year']] = df['Date(dd:mm:yyyy)'].str.split(':',expand=True)                                #splits the date column and then joins it back together using \"-\" instead of \":\"\n","  df['Date'] = df[['Year','Month','Day']].apply(lambda x: '-'.join(x.values.astype(str)), axis=\"columns\")       #because datetime format in python does not recognize colons\n","  df['Date']= pd.to_datetime(df['Date'])                              #converts the new date column to datetime format\n","  df['Hour'] = df['Time(hh:mm:ss)'].str[:2]                           #creates Hour column using just the HH component of the Time column\n","  numeric_cols = df.select_dtypes(include=['number']).columns         #defines the numeric columns, so aggregation functions do not crash with non-numeric ones.\n","\n","  if average_type == 'daily':\n","    df = df.groupby(['AERONET_Site', 'Date'])[numeric_cols].mean()\n","  elif average_type == 'hourly':\n","    df = df.groupby(['AERONET_Site', 'Date','Hour'])[numeric_cols].mean()\n","  else:\n","    average_type = 'daily'\n","    df = df.groupby(['AERONET_Site', 'Date']).mean()\n","    print(\"\\nIncorrect input for average type. Defaulting to daily averages.\")\n","\n","else:\n","  print(\"No data to parse. Please retry with different parameters.\")"]},{"cell_type":"markdown","metadata":{"id":"AQPcXhn81AEp"},"source":["**AOD Wavelength or Angstrom Exponent Selection**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ceE04Eg9S8ca"},"outputs":[],"source":["AOD_col = [col for col in df.columns if 'AOD_' in col and 'nm' in col] #list of AOD columns, used for mapping user input to them\n","Ang_exp_col = [col for col in df.columns if 'Angstrom_Exponent' in col] #list of Angstrom Exponent columns, used for mapping user input to them\n","\n","AOD_val = [int(re.search(r'\\d+', col).group()) for col in AOD_col] #expected user input choices for AOD\n","Ang_exp_val = [item.split('_')[0] for item in Ang_exp_col] #expected user input choices for AE\n","Ang_exp_val[-1] += '(Polar)' #manually adds the polar channel to the list\n","\n","if feature_choice == 1:\n","  if wavelength in AOD_val:             #if user input for AOD wavelength matches a value in the list, code proceeds forward. Otherwise it prompts user to try again\n","    for i in range(len(AOD_col)):\n","      if wavelength == AOD_val[i]:      #code scans the list of columns and list of possible values, and matches user input to the appropriate column name\n","        df = df[['Site_Latitude','Site_Longitude', AOD_col[i]]]         #if a match exists, the column name is matched to the actual column and it is then appended to the dataset\n","  else:\n","    df = df[['Site_Latitude','Site_Longitude','AOD_500nm']]\n","    print(\"\\nInput for AOD wavelength is not in list. Defaulting to 500nm.\")\n","elif feature_choice == 2:\n","  if Angstrom_exp in Ang_exp_val:     #if user input for Angstrom Exponent matches a value in the list, code proceeds forward. Otherwise it prompts user to try again\n","    for i in range(len(Ang_exp_col)):\n","      if Angstrom_exp == Ang_exp_val[i]:  #code scans the list of columns and list of possible values, and matches user input to the appropriate column nam\n","        df = df[['Site_Latitude','Site_Longitude', Ang_exp_col[i]]]     #if a match exists, the column name is matched to the actual column and it is then appended to the dataset\n","  else:\n","    df = df[['Site_Latitude','Site_Longitude','440-675']]\n","    print(\"\\nInput for Angstrom Exponent is not in list. Defaulting to 440-675.\")\n","else:\n","  feature_choice == 1\n","  print(\"\\nIncorrect input for feature choice. Defaulting to AOD.\")\n","  if wavelength in AOD_val:             #if user input for AOD wavelength matches a value in the list, code proceeds forward. Otherwise it prompts user to try again\n","    for i in range(len(AOD_col)):\n","      if wavelength == AOD_val[i]:      #code scans the list of columns and list of possible values, and matches user input to the appropriate column name\n","        df = df[['Site_Latitude','Site_Longitude', AOD_col[i]]]         #if a match exists, the column name is matched to the actual column and it is then appended to the dataset\n","  else:\n","    df = df[['Site_Latitude','Site_Longitude','AOD_500nm']]\n","    print(\"\\nInput for AOD wavelength is not in list. Defaulting to 500nm.\")\n","\n","df = df.dropna() #Drops NaN or -999.0 values\n","df = df.reset_index() #resets the index\n","df"]},{"cell_type":"markdown","metadata":{"id":"ljIb-ciOrPLj"},"source":["**Interactive Map - PlateCarree Projection**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CKW1aIw_CwT9"},"outputs":[],"source":["geo_df = deepcopy(df)\n","projection = ccrs.PlateCarree()\n","colbar = 'RdYlGn_r'\n","\n","def plot_date(date_index):\n","    fig, ax = plt.subplots(figsize=(16, 12), subplot_kw={'projection': projection}, frameon=True)\n","    ax.set_extent([lon1,lon2,lat1,lat2],crs=ccrs.PlateCarree())\n","\n","    countries = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n","    countries.plot(color=\"lightgrey\", ax=ax, zorder=0, alpha=0.1)\n","\n","    selected_date = date_list[date_index]\n","    selected_data = geo_df.loc[geo_df['Date'] == selected_date].reset_index(drop=True)\n","\n","    colbar = plt.cm.get_cmap('RdYlGn_r')\n","    colbar.set_extremes(under='gray', over='magenta')\n","    cm = ax.scatter(x=selected_data[\"Site_Longitude\"], y=selected_data[\"Site_Latitude\"],\n","                    c=selected_data[selected_data.columns[-1]],\n","                    cmap=colbar, vmin=vis_min, vmax=vis_max, s=200, zorder=1)\n","\n","    formatted_date = pd.to_datetime(selected_date).strftime('%Y-%m-%d')\n","    ax.set_title(formatted_date, size=20, weight='bold')\n","    ax.coastlines(resolution='10m', zorder=0)\n","    ax.add_feature(cfeature.STATES.with_scale('10m'), linewidth=0.5, edgecolor='lightgray', zorder=0)\n","    ax.add_feature(cfeature.BORDERS.with_scale('10m'), linewidth=0.5, edgecolor='lightgray', zorder=0)\n","\n","    cax = fig.add_axes([ax.get_position().x1 + 0.01, ax.get_position().y0, 0.02, ax.get_position().height])\n","    cbar = plt.colorbar(cm, cax=cax, extend='both')\n","    cax.set_ylabel(geo_df.columns[-1], size=20, weight='bold')\n","    tick_font_size = 20\n","    cbar.ax.tick_params(labelsize=tick_font_size)\n","    plt.show()\n","\n","def plot_datetime(date_index, hour_index):\n","    selected_date = date_list[date_index]\n","    selected_hour = hour_list[hour_index]\n","\n","    selected_data = geo_df[(geo_df['Date'] == selected_date) & (geo_df['Hour'] == selected_hour)].reset_index(drop=True)\n","\n","    fig, ax = plt.subplots(figsize=(16, 12), subplot_kw={'projection': projection}, frameon=True)\n","    plt.xlim([lon1, lon2])\n","    plt.ylim([lat1, lat2])\n","\n","    countries = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n","    countries.plot(color=\"lightgrey\", ax=ax, zorder=0, alpha=0.1)\n","\n","    colbar = plt.cm.get_cmap('RdYlGn_r')\n","    colbar.set_extremes(under='gray', over='magenta')\n","    cm = ax.scatter(x=selected_data[\"Site_Longitude\"], y=selected_data[\"Site_Latitude\"],\n","                    c=selected_data[selected_data.columns[-1]],\n","                    cmap=colbar, vmin=vis_min, vmax=vis_max, s=200, zorder=1)\n","\n","    formatted_date = pd.to_datetime(selected_date).strftime('%Y-%m-%d')\n","    formatted_time = pd.to_datetime(selected_hour, format='%H').strftime('%H:%M:%S')\n","    ax.set_title(f'{formatted_date} {formatted_time} GMT', size=20, weight='bold')\n","    ax.coastlines(resolution='10m', zorder=0)\n","    ax.add_feature(cfeature.STATES.with_scale('10m'), linewidth=0.5, edgecolor='lightgray', zorder=0)\n","    ax.add_feature(cfeature.BORDERS.with_scale('10m'), linewidth=0.5, edgecolor='lightgray', zorder=0)\n","\n","    cax = fig.add_axes([ax.get_position().x1 + 0.01, ax.get_position().y0, 0.02, ax.get_position().height])\n","    cbar = plt.colorbar(cm, cax=cax, extend='both')\n","    cax.set_ylabel(geo_df.columns[-1], size=20, weight='bold')\n","    tick_font_size = 20\n","    cbar.ax.tick_params(labelsize=tick_font_size)\n","    plt.show()\n","\n","def display_date_map(selected_date):\n","    date_index = date_labels.index(selected_date)\n","    plot_date(date_index)\n","\n","def display_datetime_map(selected_date, selected_hour):\n","    date_index = date_labels.index(selected_date)\n","    hour_index = hour_labels.index(selected_hour)\n","    plot_datetime(date_index, hour_index)\n","\n","if average_type == 'daily':\n","  date_list = sorted(geo_df['Date'].unique())\n","  date_labels = [pd.to_datetime(date).strftime('%Y-%m-%d') for date in date_list]\n","  date_slider = widgets.SelectionSlider(options=date_labels, description='Date')\n","  interact(display_date_map, selected_date=date_slider)\n","\n","elif average_type == 'hourly':\n","  date_list = sorted(geo_df['Date'].unique())\n","  hour_list = sorted(geo_df['Hour'].unique())\n","\n","  date_labels = [pd.to_datetime(date).strftime('%Y-%m-%d') for date in date_list]\n","  hour_labels = [datetime.datetime.strptime(hour_str, '%H').strftime(\"%H:%M:%S\") for hour_str in hour_list]\n","  date_slider = widgets.SelectionSlider(options=date_labels, description='Date')\n","  hour_slider = widgets.SelectionSlider(options=hour_labels, description='Hour')\n","\n","  interact(display_datetime_map, selected_date=date_slider, selected_hour=hour_slider)\n","\n","elif average_type == 'total':\n","  fig, ax = plt.subplots(figsize=(16,12),subplot_kw={'projection': projection},frameon=True)\n","  countries = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n","  countries.plot(color=\"lightgrey\",ax=ax,zorder=0,alpha=0.1)\n","  ax.coastlines(resolution='10m',zorder=1)\n","  ax.add_feature(cfeature.STATES.with_scale('10m'), linewidth=0.5, edgecolor='lightgray',zorder=1)\n","  ax.add_feature(cfeature.BORDERS.with_scale('10m'), linewidth=0.5, edgecolor='lightgray',zorder=1)\n","  plt.xlim([lon1,lon2])\n","  plt.ylim([lat1,lat2])\n","  colbar = plt.cm.get_cmap('RdYlGn_r')\n","  colbar.set_extremes(under='gray',over='magenta')\n","  cm = ax.scatter(x=geo_df[\"Site_Longitude\"], y=geo_df[\"Site_Latitude\"],\n","                    c=geo_df[geo_df.columns[-1]],\n","                cmap=colbar, vmin = vis_min, vmax = vis_max, s = 200, zorder=1)\n","  ax.set_title(\"Site Average\",size=20, weight='bold')\n","  cax = fig.add_axes([ax.get_position().x1+0.01,ax.get_position().y0,0.02,ax.get_position().height])\n","  cbar=plt.colorbar(cm, cax=cax, extend = 'both')\n","  cax.set_ylabel(geo_df.columns[-1], size=20, weight='bold')\n","  tick_font_size = 20\n","  cbar.ax.tick_params(labelsize=tick_font_size)\n","  plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Wvm62rDn2KLg"},"source":["**Interactive Map - Orthographic Projection**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lssD2T9B2LzF"},"outputs":[],"source":["geo_df = deepcopy(df)\n","\n","central_longitude = lon1 + abs(lon2 - lon2)//2\n","central_latitude  = lat1 + abs(lat1 - lat2)//2\n","projection=ccrs.Orthographic(central_longitude=central_longitude, central_latitude=central_latitude)\n","colbar='RdYlGn_r'\n","\n","def plot_date(date_index):\n","    fig, ax = plt.subplots(figsize=(12, 9), subplot_kw={'projection': projection}, frameon=True)\n","    ax.set_extent([lon1, lon2, lat1, lat2], crs=ccrs.PlateCarree())\n","\n","    countries = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n","    countries.plot(color=\"lightgrey\", ax=ax, zorder=0, alpha=0.1)\n","\n","    selected_date = date_list[date_index]\n","    selected_data = geo_df.loc[geo_df['Date'] == selected_date].reset_index(drop=True)\n","\n","    colbar = plt.cm.get_cmap('RdYlGn_r')\n","    colbar.set_extremes(under='gray', over='magenta')\n","    cm = ax.scatter(x=selected_data[\"Site_Longitude\"], y=selected_data[\"Site_Latitude\"],\n","                    c=selected_data[selected_data.columns[-1]],\n","                    cmap=colbar, vmin=vis_min, vmax=vis_max, s=200, zorder=1,\n","                    transform=ccrs.PlateCarree())\n","\n","    formatted_date = pd.to_datetime(selected_date).strftime('%Y-%m-%d')\n","    ax.set_title(formatted_date, size=20, weight='bold')\n","    ax.coastlines(resolution='10m', zorder=0)\n","    ax.add_feature(cfeature.STATES.with_scale('10m'), linewidth=0.5, edgecolor='lightgray', zorder=0)\n","    ax.add_feature(cfeature.BORDERS.with_scale('10m'), linewidth=0.5, edgecolor='lightgray', zorder=0)\n","\n","    cax = fig.add_axes([ax.get_position().x1 + 0.01, ax.get_position().y0, 0.02, ax.get_position().height])\n","    cbar = plt.colorbar(cm, cax=cax, extend='both')\n","    cax.set_ylabel(geo_df.columns[-1], size=20, weight='bold')\n","    tick_font_size = 20\n","    cbar.ax.tick_params(labelsize=tick_font_size)\n","    plt.show()\n","\n","def plot_datetime(date_index, hour_index):\n","    selected_date = date_list[date_index]\n","    selected_hour = hour_list[hour_index]\n","\n","    selected_data = geo_df[(geo_df['Date'] == selected_date) & (geo_df['Hour'] == selected_hour)].reset_index(drop=True)\n","    fig, ax = plt.subplots(figsize=(12, 9), subplot_kw={'projection': projection}, frameon=True)\n","    ax.set_extent([lon1, lon2, lat1, lat2], crs=ccrs.PlateCarree())\n","\n","    countries = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n","    countries.plot(color=\"lightgrey\", ax=ax, zorder=0, alpha=0.1)\n","\n","    colbar = plt.cm.get_cmap('RdYlGn_r')\n","    colbar.set_extremes(under='gray', over='magenta')\n","    cm = ax.scatter(x=selected_data[\"Site_Longitude\"], y=selected_data[\"Site_Latitude\"],\n","                    c=selected_data[selected_data.columns[-1]],\n","                    cmap=colbar, vmin=vis_min, vmax=vis_max, s=200, zorder=1,\n","                    transform=ccrs.PlateCarree())\n","\n","    formatted_date = pd.to_datetime(selected_date).strftime('%Y-%m-%d')\n","    formatted_time = pd.to_datetime(selected_hour, format='%H').strftime('%H:%M:%S')\n","    ax.set_title(f'{formatted_date} {formatted_time} GMT', size=20, weight='bold')\n","    ax.coastlines(resolution='10m', zorder=0)\n","    ax.add_feature(cfeature.STATES.with_scale('10m'), linewidth=0.5, edgecolor='lightgray', zorder=0)\n","    ax.add_feature(cfeature.BORDERS.with_scale('10m'), linewidth=0.5, edgecolor='lightgray', zorder=0)\n","\n","    cax = fig.add_axes([ax.get_position().x1 + 0.01, ax.get_position().y0, 0.02, ax.get_position().height])\n","    cbar = plt.colorbar(cm, cax=cax, extend='both')\n","    cax.set_ylabel(geo_df.columns[-1], size=20, weight='bold')\n","    tick_font_size = 20\n","    cbar.ax.tick_params(labelsize=tick_font_size)\n","    plt.show()\n","\n","if average_type == 'daily':\n","  date_list = sorted(geo_df['Date'].unique())\n","  date_labels = [pd.to_datetime(date).strftime('%Y-%m-%d') for date in date_list]\n","  date_slider = widgets.SelectionSlider(options=date_labels, description='Date')\n","  interact(display_date_map, selected_date=date_slider)\n","\n","elif average_type == 'hourly':\n","  date_list = sorted(geo_df['Date'].unique())\n","  hour_list = sorted(geo_df['Hour'].unique())\n","\n","  date_labels = [pd.to_datetime(date).strftime('%Y-%m-%d') for date in date_list]\n","  hour_labels = [datetime.datetime.strptime(hour_str, '%H').strftime(\"%H:%M:%S\") for hour_str in hour_list]\n","  date_slider = widgets.SelectionSlider(options=date_labels, description='Date')\n","  hour_slider = widgets.SelectionSlider(options=hour_labels, description='Hour')\n","\n","  interact(display_datetime_map, selected_date=date_slider, selected_hour=hour_slider)\n","\n","elif average_type == 'total':\n","  fig, ax = plt.subplots(figsize=(12,9),subplot_kw={'projection': projection},frameon=True)\n","  ax.set_extent([lon1,lon2,lat1,lat2],crs=ccrs.PlateCarree())\n","\n","  countries = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n","  countries.plot(color=\"lightgrey\",ax=ax,zorder=0,alpha=0.1)\n","\n","  colbar = plt.cm.get_cmap('RdYlGn_r')\n","  colbar.set_extremes(under='gray',over='magenta')\n","  cm = ax.scatter(x=geo_df[\"Site_Longitude\"], y=geo_df[\"Site_Latitude\"],\n","                    c=geo_df[geo_df.columns[-1]],\n","                cmap=colbar, vmin = vis_min, vmax = vis_max, s = 200, zorder=2, transform=ccrs.PlateCarree())\n","\n","  ax.set_title(\"Site Averages\",size=20, weight='bold')\n","  ax.coastlines(resolution='10m',zorder=1)\n","  ax.add_feature(cfeature.STATES.with_scale('10m'), linewidth=0.5, edgecolor='lightgray',zorder=1)\n","  ax.add_feature(cfeature.BORDERS.with_scale('10m'), linewidth=0.5, edgecolor='lightgray',zorder=1)\n","\n","  cax = fig.add_axes([ax.get_position().x1+0.01,ax.get_position().y0,0.02,ax.get_position().height])\n","  plt.colorbar(cm, cax=cax, extend='both')\n","  cax.set_ylabel(geo_df.columns[-1], size=20, weight='bold')\n","  tick_font_size = 20\n","  cbar.ax.tick_params(labelsize=tick_font_size)\n","  plt.show()"]},{"cell_type":"markdown","metadata":{"id":"o_n3NsEStCDH"},"source":["**Animation - PlateCarree**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CQeDMP7eLcnU"},"outputs":[],"source":["geo_df = deepcopy(df)\n","projection = ccrs.PlateCarree()\n","colbar = 'RdYlGn_r'\n","\n","if average_type == 'daily':\n","  geo_df['Timestamp'] = geo_df['Date'].astype(str)\n","  geo_df.insert(3, 'Timestamp', geo_df.pop('Timestamp'))\n","  date_list = np.unique(geo_df['Timestamp'])\n","\n","if average_type == 'hourly':\n","  geo_df['Hour'] = pd.to_datetime(geo_df['Hour'].astype(str), format='%H')\n","  geo_df['Hour'] = geo_df['Hour'].dt.time\n","  geo_df['Date_Time'] = pd.to_datetime(geo_df['Date'].astype(str) + ' ' + geo_df['Hour'].astype(str))\n","  geo_df['Timestamp'] = geo_df[['Date_Time']].astype(str)\n","  geo_df = geo_df.drop(columns=['Date', 'Hour', 'Date_Time'])\n","  geo_df.insert(3, 'Timestamp', geo_df.pop('Timestamp'))\n","  date_list = np.unique(geo_df['Timestamp'])\n","\n","fig, ax = plt.subplots(figsize=(14, 6), subplot_kw={'projection': projection}, frameon=True)\n","fig.subplots_adjust(left=0.05, right=0.9, top=0.95, bottom=0.05)\n","plt.close(fig)\n","\n","def update_plot(frame):\n","    ax.clear()\n","    geo_df_frame = geo_df[geo_df['Timestamp'] == date_list[frame]].reset_index(drop=True)\n","\n","    ax.set_xlim([lon1, lon2])\n","    ax.set_ylim([lat1, lat2])\n","\n","    countries = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n","    countries.plot(color=\"lightgrey\", ax=ax, zorder=0, alpha=0.1)\n","\n","    colbar = plt.cm.get_cmap('RdYlGn_r')\n","    colbar.set_extremes(under='gray', over='magenta')\n","    sc = ax.scatter(x=geo_df_frame[\"Site_Longitude\"], y=geo_df_frame[\"Site_Latitude\"],\n","                    c=geo_df_frame[geo_df_frame.columns[-1]],\n","                    cmap=colbar, vmin=vis_min, vmax=vis_max, s=200, zorder=1)\n","\n","    ax.set_title(date_list[frame], size=20, weight='bold')\n","    ax.coastlines(resolution='10m', zorder=0)\n","    ax.add_feature(cfeature.STATES.with_scale('10m'), linewidth=0.5, edgecolor='lightgray', zorder=0)\n","    ax.add_feature(cfeature.BORDERS.with_scale('10m'), linewidth=0.5, edgecolor='lightgray', zorder=0)\n","\n","    cax = fig.add_axes([ax.get_position().x1 + 0.01, ax.get_position().y0, 0.02, ax.get_position().height])\n","    cbar = plt.colorbar(sc, cax=cax, extend='both')\n","    cax.set_ylabel(geo_df_frame.columns[-1], size=20, weight='bold')\n","    tick_font_size = 20\n","    cbar.ax.tick_params(labelsize=tick_font_size)\n","\n","ani = animation.FuncAnimation(fig, update_plot, frames=len(date_list), repeat=False)\n","out = display(HTML(\"\"), display_id=\"animation\")\n","out.update(HTML(ani.to_jshtml()))"]},{"cell_type":"markdown","metadata":{"id":"mMTJwwuYvlZf"},"source":["**Animation - Orthographic**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FjPLBvnsvjBG"},"outputs":[],"source":["geo_df = deepcopy(df)\n","central_longitude = lon1 + abs (lon2 - lon2)//2\n","central_latitude  = lat1 + abs (lat1 - lat2)//2\n","projection=ccrs.Orthographic(central_longitude=central_longitude, central_latitude=central_latitude)\n","colbar='RdYlGn_r'\n","\n","if average_type == 'daily':\n","  geo_df['Timestamp'] = geo_df['Date'].astype(str)\n","  geo_df.insert(3, 'Timestamp', geo_df.pop('Timestamp'))\n","  date_list = np.unique(geo_df['Timestamp'])\n","\n","if average_type == 'hourly':\n","  geo_df['Hour'] = pd.to_datetime(geo_df['Hour'].astype(str), format='%H')\n","  geo_df['Hour'] = geo_df['Hour'].dt.time\n","  geo_df['Date_Time'] = pd.to_datetime(geo_df['Date'].astype(str) + ' ' + geo_df['Hour'].astype(str))\n","  geo_df['Timestamp'] = geo_df[['Date_Time']].astype(str)\n","  geo_df = geo_df.drop(columns=['Date', 'Hour', 'Date_Time'])\n","  geo_df.insert(3, 'Timestamp', geo_df.pop('Timestamp'))\n","  date_list = np.unique(geo_df['Timestamp'])\n","\n","fig, ax = plt.subplots(figsize=(10, 8), subplot_kw={'projection': projection}, frameon=True)\n","fig.subplots_adjust(left=0.05, right=0.9, top=0.95, bottom=0.05)\n","plt.close(fig)\n","\n","def update_plot(frame):\n","    ax.clear()\n","    ax.set_extent([lon1,lon2,lat1,lat2],crs=ccrs.PlateCarree())\n","    geo_df_frame = geo_df[geo_df['Timestamp'] == date_list[frame]].reset_index(drop=True)\n","\n","    countries = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n","    countries.plot(color=\"lightgrey\", ax=ax, zorder=0, alpha=0.1)\n","\n","    colbar = plt.cm.get_cmap('RdYlGn_r')\n","    colbar.set_extremes(under='gray', over='magenta')\n","    sc = ax.scatter(x=geo_df_frame[\"Site_Longitude\"], y=geo_df_frame[\"Site_Latitude\"],\n","                    c=geo_df_frame[geo_df_frame.columns[-1]],\n","                    cmap=colbar, vmin=vis_min, vmax=vis_max, s=200, zorder=1,transform=ccrs.PlateCarree())\n","\n","    ax.set_title(date_list[frame], size=20, weight='bold')\n","    ax.coastlines(resolution='10m', zorder=0)\n","    ax.add_feature(cfeature.STATES.with_scale('10m'), linewidth=0.5, edgecolor='lightgray', zorder=0)\n","    ax.add_feature(cfeature.BORDERS.with_scale('10m'), linewidth=0.5, edgecolor='lightgray', zorder=0)\n","\n","    cax = fig.add_axes([ax.get_position().x1 + 0.01, ax.get_position().y0, 0.02, ax.get_position().height])\n","    cbar = plt.colorbar(sc, cax=cax, extend='both')\n","    cax.set_ylabel(geo_df_frame.columns[-1], size=20, weight='bold')\n","    tick_font_size = 20\n","    cbar.ax.tick_params(labelsize=tick_font_size)\n","\n","ani = animation.FuncAnimation(fig, update_plot, frames=len(date_list), repeat=False)\n","out = display(HTML(\"\"), display_id=\"animation\")\n","out.update(HTML(ani.to_jshtml()))"]}],"metadata":{"colab":{"provenance":[{"file_id":"1137sHLtyfV8Y9n3M97nJEjMjn8Xi7oDC","timestamp":1695408197146},{"file_id":"1FIhxt_vHv_c-NM-zzqllTuyiTfmOoAWF","timestamp":1687836455523},{"file_id":"1iEED1qbaSd9K4kq4iPlIz8pKHB_vZ8xh","timestamp":1687181710931},{"file_id":"1kohDXtxZUANrGkkbl5YpPQ4i_UAB_qe9","timestamp":1687094628663}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}