{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"13rh2XIf2LqKm_VHcBcqeCxMGzhuxCm_M","timestamp":1721938840233},{"file_id":"1kHubbJxxjaWoT9lsDVcgA3TSMMdxQKfl","timestamp":1690133451219}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"6TjFLdFV7o3R"},"source":["- **Module:** VIIRS_AERONET_Coll\n","- **Authors:** Alqamah Sayeed and Pawan Gupta\n","- **Organization:** NASA AERONET (https://aeronet.gsfc.nasa.gov/)\n","- **Date:** 08/02/2023\n","- **Last Revision:** 08/01/2024\n","- **Purpose:** Comparing VIIRS and AERONET AODs\n","- **Disclaimer:** The code is for demonstration purposes only. Users are responsible to check for accuracy and revise to fit their objective.\n","- **Contact:** Report any concern or question related to the code to pawan.gupta@nasa.gov or petar.t.grigorov@nasa.gov\n","- **Readme:** https://github.com/pawanpgupta/AERONET/blob/Python/CODES/VIIRS_AERONET_Comparison.ipynb\n","\n"]},{"cell_type":"markdown","source":["**Mount Google Drive**"],"metadata":{"id":"surRsiWPeCAs"}},{"cell_type":"code","metadata":{"id":"cXtxOJN-ob8S"},"source":["#Mount drive to save files there\n","#clone the repository to access files from there\n","#pull the latest\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Installing Required Libraries**"],"metadata":{"id":"vuJVlmoxbFta"}},{"cell_type":"code","metadata":{"id":"gG9b8yQK3s3O"},"source":["!pip install netCDF4\n","!pip install xarray\n","\n","import numpy as np\n","import sys\n","import pandas as pd\n","import xarray as xr\n","import os\n","import requests\n","import warnings\n","import math\n","from scipy.stats import linregress\n","from sklearn.metrics import mean_squared_error as MSE\n","from scipy.interpolate import CubicSpline\n","import matplotlib.pyplot as plt\n","warnings.filterwarnings('ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Helper Function to get spatial average n x n (5 x 5 ; in this case ) average**"],"metadata":{"id":"UL8ZJk8ieZYa"}},{"cell_type":"code","source":["def moving_average_with_nan_2D(arr,w):\n","\n","    I,J = np.shape(arr)\n","    # add padding\n","    pad = w-1\n","\n","    bds = pad//2\n","    arr2 = np.zeros((I+pad,J+pad))*np.nan\n","    arr2[bds:-bds,bds:-bds]=arr\n","\n","    #Create mask\n","    mx = np.ma.masked_array(arr2,np.isnan(arr2))\n","\n","    #Sum along axis-1\n","    ret = np.cumsum(mx.filled(0) ,axis=1)\n","\n","    #count and sum along axis\n","    counts = np.cumsum(~mx.mask, axis=1)\n","\n","    #create empty variables\n","    sum_    = np.zeros((I,J))*np.nan\n","    counts2 = np.zeros((I,J))*np.nan\n","\n","    for j in range(J):\n","        sum_[:,j] = (ret[:,j+pad]-ret[:,max(0,j-1)])[bds:-bds]\n","        counts2[:,j] = (counts[:,j+pad]-counts[:,max(0,j-1)])[bds:-bds]\n","\n","    #Step 2 Processing along rows\n","    arr2 = np.zeros((I+pad,J+pad))*np.nan\n","    arr2[bds:-bds,bds:-bds]=sum_\n","    mx = np.ma.masked_array(arr2,np.isnan(arr2))\n","\n","    k2 = np.zeros((I+pad,J+pad))*np.nan\n","    k2[bds:-bds,bds:-bds]=counts2\n","    mx2 = np.ma.masked_array(k2,np.isnan(k2))\n","\n","    ret = np.cumsum(mx.filled(0) ,axis=0)\n","    counts = np.cumsum(mx2.filled(0) ,axis=0)\n","\n","    for i in range(I):\n","        sum_[i,:] = (ret[i+pad,:]-ret[max(0,i-1),:])[bds:-bds]\n","        counts2[i,:] = (counts[i+pad,:]-counts[max(0,i-1),:])[bds:-bds]\n","\n","    avg = sum_/counts2\n","    return avg"],"metadata":{"id":"DbTxF-ZPyJzw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Helper function to return actual and prediction stats**"],"metadata":{"id":"secNwvk8eqGJ"}},{"cell_type":"code","source":["def compare_actual_predict_stats(actual, predict):\n","  n = actual.shape[0]\n","  [slope, intercept, r, pvalue, stderr] = linregress(actual, predict)\n","  bias = np.sum(predict - actual) / n\n","  rmse = math.sqrt(MSE(actual, predict))\n","  percent_error = np.sum(100 * ((predict - actual) / actual)) / n\n","  return [n, slope, r, bias, rmse, percent_error]"],"metadata":{"id":"xzvf5jxK27SO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Setting Up Paths and Directory**"],"metadata":{"id":"sJY9mfhf-nkd"}},{"cell_type":"code","source":["base_directory  = \"/content/drive/MyDrive/\"\n","\n","working_directory = base_directory + \"ARSET_Workshop/\"\n","if not os.path.exists(working_directory):\n","  os.makedirs(working_directory)\n","\n","url = \"https://raw.githubusercontent.com/pawanpgupta/AERONET/Python/DATA/LAADS_query.2024-08-01T14_22.csv\"\n","filename = url[-32:]\n","\n","response = requests.get(url)\n","with open(working_directory+filename, 'wb') as file:\n","    file.write(response.content)\n","\n","file_path = pd.read_csv(working_directory+filename)\n","base_url = \"https://ladsweb.modaps.eosdis.nasa.gov\""],"metadata":{"id":"kW6PpwBachzp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Download and Process VIIRS Data**"],"metadata":{"id":"lqwe95up-yG4"}},{"cell_type":"code","source":["download_path = working_directory + \"AERDT/\"\n","if not os.path.exists(download_path):\n","  os.makedirs(download_path)\n","\n","#auth = {\"Authorization\": \"Bearer eyJ0eXAiOiJKV1QiLCJvcmlnaW4iOiJFYXJ0aGRhdGEgTG9naW4iLCJzaWciOiJlZGxqd3RwdWJrZXlfb3BzIiwiYWxnIjoiUlMyNTYifQ.eyJ0eXBlIjoiVXNlciIsInVpZCI6InBhd2FucGd1cHRhIiwiZXhwIjoxNzI3NjMxNDQ0LCJpYXQiOjE3MjI0NDc0NDQsImlzcyI6IkVhcnRoZGF0YSBMb2dpbiJ9.eU4oMUb9cKVKhB7RsPAQ6z7TVqHgj6cFoUaqru_k6REX4FORhH3qB7CeLNW-4fcPM-PC2jCsIb9NGj8eEv7o2YQnyUjcT51ep6-qjz8RCZSvUHRW6XkXD3lY3wH4hVX3YqSe1J6Z9aVz9461cX4dwGyXfjWl6bK_Eeldnqasiah8FF9IllpBX1s5iGSx9Bn-tUmtdftoFuAHUHNuKcyu_Tm5gGx2lKSI3iF_s2kyViv9aekIjgAAsgeRVaWo2fb_mrFcfdcU1ywm5LAoqu4WN5zRWOYRh7uF7KxsoKYh1OnuF8puasbc_2h2kziFpMvzQG5SLcsTHPHiqN5W570a9A\"}\n","auth = {\"Authorization\": \"Bearer eyJ0eXAiOiJKV1QiLCJvcmlnaW4iOiJFYXJ0aGRhdGEgTG9naW4iLCJzaWciOiJlZGxqd3RwdWJrZXlfb3BzIiwiYWxnIjoiUlMyNTYifQ.eyJ0eXBlIjoiVXNlciIsInVpZCI6InB0Z3JpZ29yb3YiLCJleHAiOjE3Mjc2MzEzMjQsImlhdCI6MTcyMjQ0NzMyNCwiaXNzIjoiRWFydGhkYXRhIExvZ2luIn0.8fokrmWJiaDzwupM5Q65Y3NfQejaAsXtmwJoVsCpjB1hYBz1aVFPxKqMMz-grkdcRf-DRgDqjquSrvKX0VSkIesrssBXmCtlgqS8mxRDnF7-9Pz72G3h5hTw5e5AnPx_JWPpV7jekeoK6AXpUpuKnMo64OMIRXbD2C6JnXyua9wz6cEU3j1NhWcdXzbujoqKHAdIy-yOOO_vGST3o39ifEQ8UFQMw2lxofuPFFN0rMoxD9UOnNBdctOUVEG0weKnqgWnXfolrUCrMkvMQBNRY5I8XEAtvModPtpC01l1B5t0cavcqPl5fD4W61ljSS1SVOo4pTNcKSUFKsjbWAQv5w\"}\n","\n","DF = pd.DataFrame()\n","for i in range(len(file_path)):\n","  url = base_url + file_path.iloc[i,1]\n","  fn =  url[-54:]\n","  if not os.path.exists(download_path+fn):\n","    r = requests.get(url,headers=auth)\n","    with open(download_path+fn, 'wb') as f:\n","        f.write(r.content)\n","  try:\n","    ds1 = xr.open_dataset(download_path + fn,engine=\"netcdf4\",group=\"geolocation_data\")\n","    ds2 = xr.open_dataset(download_path + fn,engine=\"netcdf4\",group=\"geophysical_data\")[['Optical_Depth_Land_And_Ocean']]\n","    arr=moving_average_with_nan_2D(ds2['Optical_Depth_Land_And_Ocean'].values,5)\n","    ds2['Optical_Depth_Land_And_Ocean_5x5']=(['number_of_lines_8x8', 'number_of_pixels_8x8'],arr)\n","    dt = pd.to_datetime(fn[21:33], format=\"%Y%j.%H%M\")\n","    cords = ds1[[\"latitude\",\"longitude\"]].to_dataframe().reset_index()\n","    df = ds2.to_dataframe().reset_index()\n","    df = pd.merge(cords,df,on = ['number_of_lines_8x8', 'number_of_pixels_8x8',])\n","    df = df.drop(columns= ['number_of_lines_8x8', 'number_of_pixels_8x8',])\n","    df[\"Date_UTC\"] = dt\n","    DF = pd.concat((DF,df),axis=0)\n","    ds1.close()\n","    ds2.close()\n","  except:\n","    pass\n","\n","date_time =pd.DataFrame(DF['Date_UTC'].unique())"],"metadata":{"id":"9K6bfu2jdWbA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Download and Process AERONET Data**"],"metadata":{"id":"WpaPADzxhJa0"}},{"cell_type":"code","source":["# Defining Global Variables\n","level =15 # AERONET data level --- 15 for Level 1.5\n","#average_type=2 #daily (1), hourly (2), timeavg (3)\n","AOD_min=0.0\n","AOD_max=1.0\n","long_west,long_east,lat_south,lat_north = 65., 130., -10., 35. # Enter map boundaries; they should closely resemble the boundaries of your LAADS data"],"metadata":{"id":"YyyryK8DhLYI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aer_path = working_directory + \"AERONET/\"\n","auth   = {\"User-Agent\": None}\n","\n","cols = ['Date(dd:mm:yyyy)','Time(hh:mm:ss)','AOD_440nm','AOD_500nm','AOD_675nm',\n","    'AERONET_Site_Name','Site_Latitude(Degrees)','Site_Longitude(Degrees)']\n","\n","if not os.path.exists(aer_path):\n","  os.makedirs(aer_path)\n","\n","DF2 = pd.DataFrame()\n","for i in range(len(date_time)):\n","  date = date_time.iloc[i,0]\n","  dt_initial = date.strftime(\"%Y%m%d\")\n","  yr_initial = dt_initial[:4]\n","  mon_initial = dt_initial[4:6]\n","  day_initial = dt_initial[6:]\n","\n","  url = 'https://aeronet.gsfc.nasa.gov/cgi-bin/print_web_data_v3?year='+yr_initial+'&month='+mon_initial+'&day='+day_initial+'&year2='+yr_initial+'&month2='+mon_initial+'&day2='+day_initial+'&AOD'+str(level)+'=1&AVG=10&lat1='+str(lat_south)+'&lat2='+str(lat_north)+'&lon1='+str(long_west)+'&lon2='+str(long_east)\n","  r = requests.get(url,headers=auth)\n","\n","  with open(aer_path+dt_initial+\".txt\", 'wb') as f:\n","      f.write(r.content)\n","  df_aer = pd.read_csv(aer_path+dt_initial+\".txt\",skiprows = 7)\n","\n","  df_aer  = df_aer[cols]\n","  df_aer[\"Date_UTC\"] = pd.to_datetime(df_aer[\"Date(dd:mm:yyyy)\"].astype(str) + \" \" + df_aer[\"Time(hh:mm:ss)\"].astype(str), format=\"%d:%m:%Y %H:%M:%S\", errors='coerce')\n","  d1 = date - pd.Timedelta(30,unit='minutes')\n","  d2 = date + pd.Timedelta(30,unit='minutes')\n","  df_aer = df_aer[((df_aer.Date_UTC>d1) & (df_aer.Date_UTC<d2))]\n","  numeric_cols = df_aer.select_dtypes(include=['number']).columns\n","  df_aer = df_aer.groupby([\"AERONET_Site_Name\"])[numeric_cols].mean()\n","  df_aer[\"Date_UTC\"]=date\n","  df_aer = df_aer.reset_index()\n","  DF2 = pd.concat((DF2,df_aer),axis=0)"],"metadata":{"id":"mwb5z5UOAUM_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Collocation**"],"metadata":{"id":"fbvBGb-Nzeyc"}},{"cell_type":"code","source":["base = DF2.reset_index(drop=True)\n","DF = DF.reset_index(drop=True)\n","\n","idx = base.index\n","\n","base[\"rlat\"] = np.radians(base['Site_Latitude(Degrees)'].values)\n","base[\"rlon\"] = np.radians(base['Site_Longitude(Degrees)'].values)\n","\n","DF[\"rlat\"] = np.radians(DF[\"latitude\"].values)\n","DF[\"rlon\"] = np.radians(DF[\"longitude\"].values)\n","\n","R = 6340.0\n","\n","cols = ['latitude', 'longitude', 'Optical_Depth_Land_And_Ocean','Optical_Depth_Land_And_Ocean_5x5', 'Date_UTC2',]\n","base[['dist (in km)',\"Exp. AOD_550nm\"] + [cols]]=np.nan\n","x = [440,500,675]\n","for i in idx:\n","    y = (base[['AOD_440nm','AOD_500nm','AOD_675nm']].iloc[i,:]).values\n","    cs = CubicSpline(x, y)\n","    #xs =[550]\n","    base[\"Exp. AOD_550nm\"][i] = cs(550)\n","\n","    lat1 = base[\"rlat\"][i]\n","    lon1 = base[\"rlon\"][i]\n","    target2 = DF[DF.Date_UTC == base['Date_UTC'][i]].reset_index(drop=True)\n","\n","    d_lat = (target2[\"rlat\"] - lat1)/2\n","    d_lon = (target2[\"rlon\"] - lon1)/2\n","    a = (np.sin(d_lat))**2.0 + np.cos(lat1)*np.cos(target2[\"rlat\"]) * (np.sin(d_lon))**2.0\n","    c = 2 * np.arctan2(np.sqrt(a),np.sqrt((1-a)))\n","    d = (R *c).values\n","    i_g = np.where(d == np.nanmin(d))[0][0]\n","    base.loc[i,cols] = (target2.iloc[i_g,:][['latitude', 'longitude', 'Optical_Depth_Land_And_Ocean','Optical_Depth_Land_And_Ocean_5x5', 'Date_UTC',]]).values\n","    base[\"dist (in km)\"][i]=d[i_g]\n","\n","base = base[base[\"dist (in km)\"]<100.]\n","base = base.drop(columns=[\"rlat\",\"rlon\"])\n","base=base.reset_index(drop=True)\n","base.to_csv(working_directory+\"Collocated_DATA.csv\",index=False,na_rep=\"nan\")"],"metadata":{"id":"v1hcHauTpM1S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Plotting**"],"metadata":{"id":"WnBPaDvB_QC7"}},{"cell_type":"code","source":["df = base[['AERONET_Site_Name', 'AOD_440nm', 'AOD_500nm', 'AOD_675nm','Exp. AOD_550nm','Optical_Depth_Land_And_Ocean', 'Optical_Depth_Land_And_Ocean_5x5',]]\n","df = df.dropna(subset=['Optical_Depth_Land_And_Ocean_5x5'])\n","df[((df['Exp. AOD_550nm']>10) | (df['Exp. AOD_550nm']<0))]=np.nan\n","df = df.dropna(subset=['Exp. AOD_550nm'])"],"metadata":{"id":"jYIhJDRt1Zpf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.rcParams.update({'font.size': 20})\n","plt.rcParams[\"axes.linewidth\"] = 3\n","plt.set_cmap('jet')\n","\n","max1=5\n","bins = 100\n","\n","fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize=(12, 10))\n","fig.suptitle(\"VIIRS vs AERONET Comparision\" , fontsize=30,fontweight='bold',y=0.95)\n","x = np.array(df['Exp. AOD_550nm'].values,dtype=\"float32\")\n","y = np.array(df['Optical_Depth_Land_And_Ocean_5x5'].values,dtype=\"float32\")\n","[n, slope, r, bias, rmse, percent_error] = compare_actual_predict_stats(x, y)\n","text = '\\nN={} \\nSlope={:.3f} \\nr={:.3f} \\nBias={:.3f} \\nRMSE={:.3f}'.format(n, slope, r, bias, rmse)\n","intercept = linregress(x, y)[1]\n","x_range = np.array(list(range(0, int(x.max() + 2))))\n","ax = axes\n","dn = ax.hist2d(x, y,bins=bins,cmin=1,\n","                # norm=mpl.colors.LogNorm(),\n","                vmin=0,vmax=5,\n","                cmap=\"jet\")#,c=c, vmin=0, vmax=+5000, cmap=\"jet\")\n","ax.plot(x_range, slope * x_range + intercept, color='black', linewidth=1)\n","ax.plot([0,max1], [0,max1], \"--\",color='black', linewidth=1)\n","\n","# annotate plot\n","ax.set_xlabel('AERONET AOD at 550nm',fontsize=15,fontweight='bold')\n","ax.set_ylabel('VIIRS AOD at 550nm',fontsize=15,fontweight='bold')\n","ax.set_xlim(0,max1)#ssnp.max((actual,predict))\n","ax.set_ylim(0,max1)#ss\n","ax.text(0.1, max1, text, ha='left', va='top',fontsize=15)\n","ax.set(adjustable='box', aspect='equal')\n","plt.gca().set_aspect('equal', adjustable='box')\n","cbar=fig.colorbar(dn[3], orientation='vertical',ax=ax)#,shrink=0.75)\n","cbar.set_label('Density',labelpad=-45,y=0.5)\n","#plt.subplots_adjust(hspace = .01,wspace=0.01)\n","plt.savefig(working_directory+\"Comparison_plot.png\",bbox_inches=\"tight\")"],"metadata":{"id":"A3vvZjEN9rvY"},"execution_count":null,"outputs":[]}]}